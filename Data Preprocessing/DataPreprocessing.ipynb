{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Description\n",
    "\n",
    "Our project is to prepare a report for a bank’s loan division. We’ll need to find out if a customer’s marital status and number of children has an impact on whether they will default on a loan. The bank already has some data on customers’ credit worthiness.\n",
    "\n",
    "Our report will be considered when building a **credit scoring** of a potential customer. A ** credit scoring ** is used to evaluate the ability of a potential borrower to repay their loan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Open the data file and have a look at the general information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21525 entries, 0 to 21524\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   children          21525 non-null  int64  \n",
      " 1   days_employed     19351 non-null  float64\n",
      " 2   dob_years         21525 non-null  int64  \n",
      " 3   education         21525 non-null  object \n",
      " 4   education_id      21525 non-null  int64  \n",
      " 5   family_status     21525 non-null  object \n",
      " 6   family_status_id  21525 non-null  int64  \n",
      " 7   gender            21525 non-null  object \n",
      " 8   income_type       21525 non-null  object \n",
      " 9   debt              21525 non-null  int64  \n",
      " 10  total_income      19351 non-null  float64\n",
      " 11  purpose           21525 non-null  object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 2.0+ MB\n",
      "   children  days_employed  dob_years            education  education_id  \\\n",
      "0         1   -8437.673028         42    bachelor's degree             0   \n",
      "1         1   -4024.803754         36  secondary education             1   \n",
      "2         0   -5623.422610         33  Secondary Education             1   \n",
      "3         3   -4124.747207         32  secondary education             1   \n",
      "4         0  340266.072047         53  secondary education             1   \n",
      "\n",
      "       family_status  family_status_id gender income_type  debt  total_income  \\\n",
      "0            married                 0      F    employee     0     40620.102   \n",
      "1            married                 0      F    employee     0     17932.802   \n",
      "2            married                 0      M    employee     0     23341.752   \n",
      "3            married                 0      M    employee     0     42820.568   \n",
      "4  civil partnership                 1      F     retiree     0     25378.572   \n",
      "\n",
      "                   purpose  \n",
      "0    purchase of the house  \n",
      "1             car purchase  \n",
      "2    purchase of the house  \n",
      "3  supplementary education  \n",
      "4        to have a wedding  \n"
     ]
    }
   ],
   "source": [
    "# Read and import the file in to the dataframe dataCreditScoring\n",
    "import pandas as pd\n",
    "\n",
    "#from nltk.stem import SnowballStemmer \n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "dataCreditScoring=pd.read_csv('credit_scoring_eng.csv')\n",
    "\n",
    "#print general information of the dataframe\n",
    "dataCreditScoring.info()\n",
    "\n",
    "#print first 10 rows\n",
    "print (dataCreditScoring.head())\n",
    "\n",
    "#print (dataCreditScoring.tail())\n",
    "#print (dataCreditScoring.sample())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. By using info() method, we can check the table information like columns name, their datatype and count of null values etc. \n",
    "2. By examine the outcome, we found there are some null values in the column 'days_employed' and 'total_income'. \n",
    "3. To analyze all data in detail, we have to process the table further. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "children               0\n",
      "days_employed       2174\n",
      "dob_years              0\n",
      "education              0\n",
      "education_id           0\n",
      "family_status          0\n",
      "family_status_id       0\n",
      "gender                 0\n",
      "income_type            0\n",
      "debt                   0\n",
      "total_income        2174\n",
      "purpose                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#print all columns with null values count.\n",
    "print(dataCreditScoring.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Verifying and updating days_employed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################### Verifying and updating days_employed column #############################################\n",
      "Approx. 10% rows are missing\n",
      "Total negative Count:  15906\n",
      "Total positive Count:  3445\n",
      "No. of values fall in between the aprropriate age range of normal human being are:  0\n",
      "The Mean and Median of Days_Employed column are: 63046.497661473615 and -1203.369528770489\n"
     ]
    }
   ],
   "source": [
    "#Check all columns one by one.\n",
    "      \n",
    "###################################### 1. Verifying and updating days_employed ######################################\n",
    "print('####################### Verifying and updating days_employed column #############################################')\n",
    "      \n",
    "#Find % of missing value in days_employed \n",
    "missingCount=dataCreditScoring['days_employed'].isnull().sum()\n",
    "totalRows=len(dataCreditScoring)\n",
    "print('Approx. {:0.0%} rows are missing'.format(missingCount/totalRows))\n",
    "      \n",
    "#check all other available values in the column. \n",
    "#We saw there are some -ve and +ve values so now we find how many are +ve and -ve.   \n",
    "print('Total negative Count: ',dataCreditScoring[dataCreditScoring['days_employed']<0]['days_employed'].count()) \n",
    "print('Total positive Count: ',dataCreditScoring[(dataCreditScoring['days_employed']>0)]['days_employed'].count())\n",
    "\n",
    "#From the +ve values we try to find how many are valid values as normal person works max. for 50 to 60 years.       \n",
    "print('No. of values fall in between the aprropriate age range of normal human being are: ', dataCreditScoring[(dataCreditScoring['days_employed']>0) & (dataCreditScoring['days_employed']<40000)]['days_employed'].count())\n",
    "# No values fall in the valid range, so all data is incorrect. \n",
    "\n",
    "      \n",
    "#Now we will also check the Mean and Median\n",
    "print('The Mean and Median of Days_Employed column are: {0} and {1}'.format(dataCreditScoring['days_employed'].mean(), dataCreditScoring['days_employed'].median()))\n",
    "# There is huge difference between Mean and Median values. So it's confirmed that there are outliers in this column.\n",
    "# So before deleting the whole column we will discuss with the team who provide the data first.\n",
    "\n",
    "############################################### END #######################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Verifying and updating children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################### Verifying and updating children column  #############################################\n",
      " 5         9\n",
      " 4        41\n",
      "-1        47\n",
      " 20       76\n",
      " 3       330\n",
      " 2      2055\n",
      " 1      4818\n",
      " 0     14149\n",
      "Name: children, dtype: int64\n",
      "After Updation:\n",
      "5        9\n",
      "4       41\n",
      "3      330\n",
      "2     2131\n",
      "1     4865\n",
      "0    14149\n",
      "Name: children, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "###################################### 2. Verifying and updating children ###############################################################\n",
    "print('####################### Verifying and updating children column  #############################################')\n",
    "#print all children unique values and their count.\n",
    "print(dataCreditScoring['children'].value_counts(ascending=True))\n",
    "# found 2 rows as invalid (-1, 47) \n",
    "\n",
    "#Update the 2 records as per below condition.      \n",
    "dataCreditScoring.loc[dataCreditScoring['children']==-1, 'children']=1\n",
    "dataCreditScoring.loc[dataCreditScoring['children']==20, 'children']=2\n",
    "      \n",
    "#Verify the coulmn after updation.\n",
    "print('After Updation:')\n",
    "print(dataCreditScoring['children'].value_counts(ascending=True))\n",
    "#################################################  END ###################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Verifying and updating dob_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################### Verifying and updating dob_years column ################################################\n",
      "75      1\n",
      "74      6\n",
      "73      8\n",
      "19     14\n",
      "72     33\n",
      "20     51\n",
      "71     58\n",
      "70     65\n",
      "69     85\n",
      "68     99\n",
      "0     101\n",
      "21    111\n",
      "67    167\n",
      "22    183\n",
      "66    183\n",
      "65    194\n",
      "23    254\n",
      "24    264\n",
      "64    265\n",
      "63    269\n",
      "62    352\n",
      "61    355\n",
      "25    357\n",
      "60    377\n",
      "26    408\n",
      "55    443\n",
      "59    444\n",
      "51    448\n",
      "53    459\n",
      "57    460\n",
      "58    461\n",
      "46    475\n",
      "54    479\n",
      "47    480\n",
      "52    484\n",
      "56    487\n",
      "27    493\n",
      "45    497\n",
      "28    503\n",
      "49    508\n",
      "32    510\n",
      "43    513\n",
      "50    514\n",
      "37    537\n",
      "48    538\n",
      "30    540\n",
      "29    545\n",
      "44    547\n",
      "36    555\n",
      "31    560\n",
      "39    573\n",
      "33    581\n",
      "42    597\n",
      "38    598\n",
      "34    603\n",
      "41    607\n",
      "40    609\n",
      "35    617\n",
      "Name: dob_years, dtype: int64\n",
      "The Mean and Median of dob_years column are: 43.29337979094077 and 42.0\n",
      "             mean  median\n",
      "gender                   \n",
      "F       44.471972      44\n",
      "M       40.993825      40\n",
      "XNA     24.000000      24\n",
      "After Updation:\n",
      "75      1\n",
      "74      6\n",
      "73      8\n",
      "19     14\n",
      "72     33\n",
      "20     51\n",
      "71     58\n",
      "70     65\n",
      "69     85\n",
      "68     99\n",
      "21    111\n",
      "67    167\n",
      "22    183\n",
      "66    183\n",
      "65    194\n",
      "23    254\n",
      "24    264\n",
      "64    265\n",
      "63    269\n",
      "62    352\n",
      "61    355\n",
      "25    357\n",
      "60    377\n",
      "26    408\n",
      "55    443\n",
      "59    444\n",
      "51    448\n",
      "53    459\n",
      "57    460\n",
      "58    461\n",
      "46    475\n",
      "54    479\n",
      "47    480\n",
      "52    484\n",
      "56    487\n",
      "27    493\n",
      "45    497\n",
      "28    503\n",
      "49    508\n",
      "32    510\n",
      "43    513\n",
      "50    514\n",
      "37    537\n",
      "48    538\n",
      "30    540\n",
      "29    545\n",
      "44    547\n",
      "36    555\n",
      "31    560\n",
      "39    573\n",
      "33    581\n",
      "38    598\n",
      "34    603\n",
      "41    607\n",
      "40    609\n",
      "35    617\n",
      "42    698\n",
      "Name: dob_years, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "########################################## 3. Verifying and updating dob_years  ##########################################################\n",
    "print('####################### Verifying and updating dob_years column ################################################')\n",
    "#print all dob_years unique values and their count.\n",
    "print(dataCreditScoring['dob_years'].value_counts(ascending=True))\n",
    "#Found there are 101 rows where dob_years is 0 so need to update this\n",
    "      \n",
    "#Calculate Mean and Meadian of dob_years\n",
    "print('The Mean and Median of dob_years column are: {0} and {1}'.format(dataCreditScoring['dob_years'].mean(), dataCreditScoring['dob_years'].median()))\n",
    "#The means and medians are roughly equal, which implies that there are no outliers in the Days_Employed columns.\n",
    "      \n",
    "#now we also check mean and median by gender column \n",
    "print(dataCreditScoring.groupby('gender')['dob_years'].agg(['mean','median']))\n",
    "#there is no such big differences in the mean and medain values based on gender.\n",
    "#so we can use median value to fill the days_employed column where dob_years=0\n",
    "\n",
    "#Update missing values\n",
    "dataCreditScoring.loc[dataCreditScoring['dob_years']==0, 'dob_years']=dataCreditScoring['dob_years'].median()\n",
    "\n",
    "#Verify the coulmn after updation.\n",
    "print('After Updation:')\n",
    "print(dataCreditScoring['dob_years'].value_counts(ascending=True))\n",
    "################################################ End ######################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Verifying and updating education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################### Verifying and updating education  #######################################################\n",
      "Graduate Degree            1\n",
      "GRADUATE DEGREE            1\n",
      "graduate degree            4\n",
      "Primary Education         15\n",
      "PRIMARY EDUCATION         17\n",
      "SOME COLLEGE              29\n",
      "Some College              47\n",
      "primary education        250\n",
      "Bachelor's Degree        268\n",
      "BACHELOR'S DEGREE        274\n",
      "some college             668\n",
      "Secondary Education      711\n",
      "SECONDARY EDUCATION      772\n",
      "bachelor's degree       4718\n",
      "secondary education    13750\n",
      "Name: education, dtype: int64\n",
      "After Updation:\n",
      "primary education        282\n",
      "some college             744\n",
      "bachelor's degree       5266\n",
      "secondary education    15233\n",
      "Name: education, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "########################################## 4. Verifying and updating education  ##########################################################\n",
    "print('####################### Verifying and updating education  #######################################################')\n",
    "#print all education unique values and their count.\n",
    "print(dataCreditScoring['education'].value_counts(ascending=True)) \n",
    "#All values seems fine except 1 data i.e. graduate degree and bachelor's degree. Both are same so we update any one of them with other.\n",
    "\n",
    "#Also update all values to lower case\n",
    "dataCreditScoring['education'] = dataCreditScoring['education'].str.lower()\n",
    "\n",
    "#Replacing graduate degree with bachelor's degree.\n",
    "dataCreditScoring.loc[dataCreditScoring['education']=='graduate degree', 'education']=\"bachelor's degree\"\n",
    "\n",
    "#Verify the coulmn after updation.\n",
    "print('After Updation:')\n",
    "print(dataCreditScoring['education'].value_counts(ascending=True))\n",
    "################################################## End  ###############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Verifying and updating education_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################### Verifying and updating education_id column\n",
      "4        6\n",
      "3      282\n",
      "2      744\n",
      "0     5260\n",
      "1    15233\n",
      "Name: education_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "########################################### 5. Verifying and updating education_id  ######################################\n",
    "print('####################### Verifying and updating education_id column')\n",
    "#print all education_id unique values and their count.\n",
    "print(dataCreditScoring['education_id'].value_counts(ascending=True))# all data seems correct\n",
    "########################################## End ############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Verifying and updating family_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################### Verifying and updating family_status column\n",
      "widow / widower        960\n",
      "divorced              1195\n",
      "unmarried             2813\n",
      "civil partnership     4177\n",
      "married              12380\n",
      "Name: family_status, dtype: int64\n",
      "After Updation:\n",
      "widow / widower        960\n",
      "divorced              1195\n",
      "unmarried             2813\n",
      "civil partnership     4177\n",
      "married              12380\n",
      "Name: family_status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "########################################### 6. Verifying and updating family_status  ##########################################################\n",
    "print('####################### Verifying and updating family_status column')\n",
    "\n",
    "#print all family_status unique values and their count.\n",
    "print(dataCreditScoring['family_status'].value_counts(ascending=True))\n",
    "\n",
    "# updated all values to lower case\n",
    "dataCreditScoring['family_status'] = dataCreditScoring['family_status'].str.lower()\n",
    "\n",
    "#Verify the coulmn after updation.\n",
    "print('After Updation:')\n",
    "print(dataCreditScoring['family_status'].value_counts(ascending=True))\n",
    "############################################# End  ########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. Verifying and updating family_status_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################### Verifying and updating family_status_id column\n",
      "2      960\n",
      "3     1195\n",
      "4     2813\n",
      "1     4177\n",
      "0    12380\n",
      "Name: family_status_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "########################################### 7. Verifying and updating family_status_id  ##########################################################\n",
    "print('####################### Verifying and updating family_status_id column')\n",
    "#print all family_status unique values and their count.\n",
    "print(dataCreditScoring['family_status_id'].value_counts(ascending=True))# all data seems fine\n",
    "############################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.  Verifying and updating gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################### Verifying and updating gender column\n",
      "XNA        1\n",
      "M       7288\n",
      "F      14236\n",
      "Name: gender, dtype: int64\n",
      "       children  days_employed  dob_years     education  education_id  \\\n",
      "10701         0   -2358.600502         24  some college             2   \n",
      "\n",
      "           family_status  family_status_id gender income_type  debt  \\\n",
      "10701  civil partnership                 1    XNA    business     0   \n",
      "\n",
      "       total_income          purpose  \n",
      "10701     32624.825  buy real estate  \n"
     ]
    }
   ],
   "source": [
    "########################################## 8.  Verifying and updating gender  ##########################################################\n",
    "print('####################### Verifying and updating gender column')\n",
    "\n",
    "#print all gender unique values and their count.\n",
    "print(dataCreditScoring['gender'].value_counts(ascending=True))\n",
    "#Found 1 record with the value 'XNA' but seems someone don't wants to mention the gender so so we keep this as it is.\n",
    "print(dataCreditScoring[dataCreditScoring['gender']=='XNA'])\n",
    "\n",
    "############################################### End #######################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. Verifying and updating income_type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################### Verifying and updating income_type column\n",
      "student                            1\n",
      "paternity / maternity leave        1\n",
      "entrepreneur                       2\n",
      "unemployed                         2\n",
      "civil servant                   1459\n",
      "retiree                         3856\n",
      "business                        5085\n",
      "employee                       11119\n",
      "Name: income_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "######################################### 9. Verifying and updating income_type  ##########################################################\n",
    "print('####################### Verifying and updating income_type column')\n",
    "\n",
    "#print all income_type unique values and their count.\n",
    "print(dataCreditScoring['income_type'].value_counts(ascending=True))\n",
    "dataCreditScoring['income_type'] = dataCreditScoring['income_type'].str.lower()#just update all values in to lower case\n",
    "\n",
    "################################################ End ######################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10. Verifying and updating debt  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################### Verifying and updating debt column\n",
      "1     1741\n",
      "0    19784\n",
      "Name: debt, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "########################################## 10. Verifying and updating debt  ##########################################################\n",
    "print('####################### Verifying and updating debt column')\n",
    "#print all debt unique values and their count.\n",
    "print(dataCreditScoring['debt'].value_counts(ascending=True))#all seems correct\n",
    "\n",
    "############################################# End #########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 11. Verifying and updating total_income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################### Verifying and updating total_income column\n",
      "9591.824     1\n",
      "19232.334    1\n",
      "15710.698    1\n",
      "34774.610    1\n",
      "48796.341    1\n",
      "            ..\n",
      "26935.722    1\n",
      "54857.666    1\n",
      "42413.096    2\n",
      "31791.384    2\n",
      "17312.717    2\n",
      "Name: total_income, Length: 19348, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "######################################### 11. Verifying and updating total_income  ##########################################################\n",
    "print('####################### Verifying and updating total_income column')\n",
    "#print all total_income unique values and their count.\n",
    "print(dataCreditScoring['total_income'].value_counts(ascending=True))\n",
    "#All seems correct except for the null values. total no of null records are exact same as of days_employed column. which is logically correct.  \n",
    "\n",
    "####################################################### End ##############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 12. Verifying and updating purpose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################### Checking and Updating values in purpose column\n",
      "to become educated                          412\n",
      "getting higher education                    426\n",
      "profile education                           436\n",
      "getting an education                        443\n",
      "education                                   447\n",
      "to get a supplementary education            447\n",
      "university education                        453\n",
      "purchase of a car                           455\n",
      "car purchase                                462\n",
      "supplementary education                     462\n",
      "to buy a car                                472\n",
      "cars                                        478\n",
      "buying a second-hand car                    479\n",
      "to own a car                                480\n",
      "second-hand car purchase                    489\n",
      "car                                         495\n",
      "going to university                         496\n",
      "buying my own car                           505\n",
      "buy residential real estate                 607\n",
      "housing renovation                          612\n",
      "purchase of my own house                    620\n",
      "building a property                         620\n",
      "buy real estate                             624\n",
      "building a real estate                      626\n",
      "transactions with my real estate            630\n",
      "property                                    634\n",
      "construction of own property                635\n",
      "purchase of the house for my family         641\n",
      "purchase of the house                       647\n",
      "housing                                     647\n",
      "transactions with commercial real estate    651\n",
      "buying property for renting out             653\n",
      "housing transactions                        653\n",
      "buy commercial real estate                  664\n",
      "real estate transactions                    676\n",
      "to have a wedding                           774\n",
      "having a wedding                            777\n",
      "wedding ceremony                            797\n",
      "Name: purpose, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "###########################################  12. Verifying and updating purpose  ##########################################################\n",
    "print('####################### Checking and Updating values in purpose column')\n",
    "#update all values to lower\n",
    "dataCreditScoring['purpose']=dataCreditScoring['purpose'].str.lower()\n",
    "#print all total_income unique values and their count.\n",
    "print(dataCreditScoring['purpose'].value_counts(ascending=True))\n",
    "# Data is fine but We need to categorize the purpose data which we will do in categorizing section.\n",
    "########################################End#############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First checked all the coulmns for null value. Found null values in days_employed and total_income columns.\n",
    "2. Start analysis all column one by one. First start with days_employed column.\n",
    "3. days_employed: Around 10% data is missing and the other available data is also not valid, So before deleting the whole column we will discuss with the team who provide the data. \n",
    "\n",
    "4. children : Found 2 incorrect data (-1,20). Replace the incorrect values with correct values(1,2) as children can't be -1 and 20.\n",
    "\n",
    "5. dob_years : There are around 101 rows where values is 0, and rest of the values seems fine. After analysing we found that we can replace 0 with median values. So we updated the missing values by median. \n",
    "\n",
    "6. education : All values seems fine except 1 data i.e. 'graduate degree' and 'bachelor's degree'. As both are same so we update any one of them with the other.\n",
    "\n",
    "7. education_id : All data seems correct.\n",
    "8. family_status : Just updated all values to lower case.\n",
    "9. gender : Found 1 record with the value 'XNA' but may be someone don't wants to mention the gender so so we keep this as it is.\n",
    "\n",
    "10. income_type: Just updated all values to lower case.\n",
    "11. debt: All seems correct.\n",
    "12. total_income: All seems correct except for the null values. Total no. of null records are exact same where days_employed is also null which is logically correct.  \n",
    "13. purpose: Updated all values to lower. Data is fine but we need to categorize the purpose data which we will do in categorizng section.\n",
    "\n",
    " \n",
    "So far we have checked all the data. Except days_employed columns we have processed all columns missing values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div><b> Removing duplicates from total_income:</b>\n",
    "   <ol> \n",
    "       <li>First check total null values count of 'days_employed' and 'total_income' column </li>\n",
    "       <li>As we checked above also, data in days_employed column is invalid and also we don't need it in our further analysis, so we will leave this column as it is for now.</li>\n",
    "       <li>Finally we fill total_income null values by the median value. To calculate median we first group the total_income by income_type and then calculate median.</li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2174\n"
     ]
    }
   ],
   "source": [
    "#checking for none values in total_income column\n",
    "print(dataCreditScoring['total_income'].isnull().sum())\n",
    "#print(dataCreditScoring.groupby('income_type')['total_income'].agg(['mean','median','sum']))\n",
    "\n",
    "#Replacing the null values.\n",
    "dataCreditScoring['total_income']=dataCreditScoring.groupby('income_type')['total_income'].transform(\n",
    "    lambda x: x.fillna(x.median())\n",
    "    )\n",
    "#print(dataCreditScoring['total_income'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data type replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21525 entries, 0 to 21524\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   children          21525 non-null  int8   \n",
      " 1   days_employed     19351 non-null  float64\n",
      " 2   dob_years         21525 non-null  int8   \n",
      " 3   education         21525 non-null  object \n",
      " 4   education_id      21525 non-null  int16  \n",
      " 5   family_status     21525 non-null  object \n",
      " 6   family_status_id  21525 non-null  int16  \n",
      " 7   gender            21525 non-null  object \n",
      " 8   income_type       21525 non-null  object \n",
      " 9   debt              21525 non-null  int64  \n",
      " 10  total_income      21525 non-null  float64\n",
      " 11  purpose           21525 non-null  object \n",
      "dtypes: float64(2), int16(2), int64(1), int8(2), object(5)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#Update Data Types of some columns. \n",
    "dataCreditScoring['children'] = dataCreditScoring['children'].astype('int8')\n",
    "dataCreditScoring['dob_years'] = dataCreditScoring['dob_years'].astype('int8')\n",
    "dataCreditScoring['education_id'] = dataCreditScoring['education_id'].astype('int16')\n",
    "dataCreditScoring['family_status_id'] = dataCreditScoring['family_status_id'].astype('int16')\n",
    "dataCreditScoring['education'] = dataCreditScoring['education'].astype('str')\n",
    "#verify the updation.\n",
    "dataCreditScoring.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After analyzing the data we also found there are some columns for which we can replace data type. like for children column we don't need int64 data type. So we change the data types to int8.\n",
    "\n",
    "We can also see the impact of doing so by executing info(). Now after replacing data types, memory usage has dropped to 1.4 from 2.0. thats looks great."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of duplicate records : 72\n",
      "Deleted duplicate records.\n",
      "Duplicate records left : 0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21453 entries, 0 to 21452\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   children          21453 non-null  int8   \n",
      " 1   days_employed     19351 non-null  float64\n",
      " 2   dob_years         21453 non-null  int8   \n",
      " 3   education         21453 non-null  object \n",
      " 4   education_id      21453 non-null  int16  \n",
      " 5   family_status     21453 non-null  object \n",
      " 6   family_status_id  21453 non-null  int16  \n",
      " 7   gender            21453 non-null  object \n",
      " 8   income_type       21453 non-null  object \n",
      " 9   debt              21453 non-null  int64  \n",
      " 10  total_income      21453 non-null  float64\n",
      " 11  purpose           21453 non-null  object \n",
      "dtypes: float64(2), int16(2), int64(1), int8(2), object(5)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#printing the count of all duplicate records\n",
    "print('No. of duplicate records : {0}'.format(dataCreditScoring.duplicated().sum()))\n",
    "#found 72 duplicate records. \n",
    "\n",
    "#deletes all duplicates \n",
    "print('Deleted duplicate records.')\n",
    "dataCreditScoring=dataCreditScoring.drop_duplicates().reset_index(drop=True) \n",
    "\n",
    "#verify after deleting the duplicates records.\n",
    "print('Duplicate records left : {0}'.format(dataCreditScoring.duplicated().sum()))\n",
    "\n",
    "dataCreditScoring.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have deleted the duplicate records but if we see the purpose column we can easily see some purpose are similar in nature but may be due to their text it is recorded as different or the same person has applied for another loan for same purpose.\n",
    "Anyways our task is to calculate whether the customer is defaulted on a loan based on their marital status and number of children, So in our next task we will categorize purpose column to common type and then delete all duplicate rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate records count : 252\n",
      "Deleted duplicate reords\n",
      "Duplicate records left : 0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 21201 entries, 0 to 21452\n",
      "Data columns (total 13 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   children              21201 non-null  int8   \n",
      " 1   days_employed         19351 non-null  float64\n",
      " 2   dob_years             21201 non-null  int8   \n",
      " 3   education             21201 non-null  object \n",
      " 4   education_id          21201 non-null  int16  \n",
      " 5   family_status         21201 non-null  object \n",
      " 6   family_status_id      21201 non-null  int16  \n",
      " 7   gender                21201 non-null  object \n",
      " 8   income_type           21201 non-null  object \n",
      " 9   debt                  21201 non-null  int64  \n",
      " 10  total_income          21201 non-null  float64\n",
      " 11  purpose_main          21201 non-null  object \n",
      " 12  dataCreditScoring_ID  21201 non-null  int64  \n",
      "dtypes: float64(2), int16(2), int64(2), int8(2), object(5)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "#create a function which will take purpose as input parameter and return some common purpose text which we will add as\n",
    "#separate column in the the dataframe.\n",
    "#from nltk.stem import SnowballStemmer \n",
    "english_stemmer = SnowballStemmer('english')\n",
    "def define_Purpose(dataPurpose):\n",
    "    for word in dataPurpose.split(' '):\n",
    "        try:\n",
    "            \n",
    "            stemmed_word = english_stemmer.stem(word)\n",
    "            #print(stemmed_word)\n",
    "            if ((stemmed_word =='educ') | (stemmed_word =='univers')):\n",
    "                return 'education'\n",
    "            if stemmed_word =='car':\n",
    "                return 'car'\n",
    "            if stemmed_word =='hous':\n",
    "                return 'house'\n",
    "            if stemmed_word =='wed':\n",
    "                return 'wedding'\n",
    "            if ((stemmed_word =='estat') | (stemmed_word =='properti')):\n",
    "                return 'real estate'\n",
    "        except:\n",
    "            return word\n",
    "            \n",
    "\n",
    "#aaa=define_Purpose('wedding is a special event')\n",
    "#print(aaa)\n",
    "try:\n",
    "    \n",
    "    #calling 'define_Purpose' function and add separate column 'purpose_main' in the dataframe for new purpose.\n",
    "    dataCreditScoring['purpose_main']=dataCreditScoring['purpose'].apply(define_Purpose)\n",
    "\n",
    "    #now check duplicate records using 'purpose_main' column and excluding 'purpose' column.\n",
    "    print('Duplicate records count : {0}'.format(dataCreditScoring[['children','days_employed','dob_years','education','education_id','family_status','family_status_id','gender','income_type','debt','total_income','purpose_main']].duplicated().sum()))\n",
    "    #there are 252 duplicate rows, so we will delete all those.\n",
    "   \n",
    "    #Add dataCreditScoring_ID column and create new dataframe with dataCreditScoring_ID and purpose column so that we have \n",
    "    #back up of old purpose before adding the new purpose.\n",
    "    dataCreditScoring['dataCreditScoring_ID']=dataCreditScoring.index+1\n",
    "    dataCreditScoring_purpose=dataCreditScoring[['dataCreditScoring_ID','purpose']]\n",
    "   \n",
    "    #After taking back up now drop old purpose column \n",
    "    dataCreditScoring.drop(['purpose'], axis=1,inplace=True)\n",
    "\n",
    "    #deletes all duplicates \n",
    "    dataCreditScoring=dataCreditScoring.drop_duplicates(subset=['children','days_employed','dob_years','education','education_id','family_status','family_status_id','gender','income_type','debt','total_income','purpose_main'], keep='first')\n",
    "    print('Deleted duplicate reords')\n",
    "except:\n",
    "    print('Already executed code.')\n",
    "#Print duplicates records again to verify that no duplicates records left\n",
    "print('Duplicate records left : {0}'.format(dataCreditScoring[['children','days_employed','dob_years','education','education_id','family_status','family_status_id','gender','income_type','debt','total_income','purpose_main']].duplicated().sum()))\n",
    "\n",
    "#verify the updation.\n",
    "dataCreditScoring.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we have categorize the purpose column. By categorizing we get 252 duplicate rows which we have deleted.\n",
    "So far we have updated the missing values, changed the required data types and deleted the duplicated rows. \n",
    "Now we got the data for analysing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Answer these questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is there a relation between having kids and repaying a loan on time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isDefaulter  Nodefaulter  defaulter  % of defaulter\n",
      "children                                           \n",
      "0                12824.0     1062.0            7.65\n",
      "3                  302.0       27.0            8.21\n",
      "1                 4373.0      445.0            9.24\n",
      "2                 1916.0      202.0            9.54\n",
      "4                   37.0        4.0            9.76\n",
      "5                    9.0        NaN             NaN\n"
     ]
    }
   ],
   "source": [
    "#create function which will return Nodefaulter/defaulter based on isdebt column.\n",
    "def define_Debt(isdebt):\n",
    "        try:\n",
    "            if isdebt==0:\n",
    "                return 'Nodefaulter'\n",
    "            if isdebt==1:\n",
    "                return 'defaulter'\n",
    "        except:\n",
    "            return word\n",
    "        \n",
    "#added new column 'isDefaulter' to the dataframe.\n",
    "dataCreditScoring['isDefaulter']=dataCreditScoring['debt'].apply(define_Debt)\n",
    "\n",
    "#Creating pivot table to present the result in particulare format.\n",
    "data_pivot = dataCreditScoring.pivot_table(index='children', columns='isDefaulter', values='debt', aggfunc='count')\n",
    "data_pivot['% of defaulter'] = (data_pivot['defaulter']/(data_pivot['Nodefaulter']+data_pivot['defaulter'])*100).round(2)\n",
    "print(data_pivot.sort_values('% of defaulter')) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis are as follows:\n",
    "1. Maximum people who take loan belongs to the category of those who don't have children. May be generally people take loan in their ealry age also if we see the % of defaulter it is the least among all. So people pays loan on time when they don't have kids.\n",
    "\n",
    "2. If we move to next rows i.e. more children means more probability of defaulter but with 5 children nobody is dafaulter. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is there a relation between marital status and repaying a loan on time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isDefaulter        Nodefaulter  defaulter  % of defaulter\n",
      "family_status                                            \n",
      "widow / widower            886         63            6.64\n",
      "divorced                  1108         85            7.12\n",
      "married                  11211        930            7.66\n",
      "civil partnership         3738        388            9.40\n",
      "unmarried                 2518        274            9.81\n"
     ]
    }
   ],
   "source": [
    "#Creating pivot table to present the result in particulare format.\n",
    "data_pivot_family = dataCreditScoring.pivot_table(index='family_status', columns='isDefaulter', values='debt', aggfunc='count')\n",
    "data_pivot_family['% of defaulter'] = (data_pivot_family['defaulter']/(data_pivot_family['Nodefaulter']+data_pivot_family['defaulter'])*100).round(2)\n",
    "print(data_pivot_family.sort_values('% of defaulter')) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Widow / widower category's people generally pays loan on time.\n",
    "2. Even Divorced people's '% of defaulter' is less than Married, civil partnership and unmarried.\n",
    "3. Most of the person belongs to Married category and are still less in '% of defaulter' than civil partnership and unmarried."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is there a relation between income level and repaying a loan on time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isDefaulter     Nodefaulter  defaulter  % of defaulter\n",
      "income_group                                          \n",
      "80k-120k              163.0       10.0            5.78\n",
      "30k-50k              5276.0      422.0            7.41\n",
      "120k-200k              35.0        3.0            7.89\n",
      "0-30k               13977.0     1304.0            8.53\n",
      "more than 300k          1.0        1.0           50.00\n",
      "200k-300k               9.0        NaN             NaN\n"
     ]
    }
   ],
   "source": [
    "#We’ll count how many defaulters of each income there are using the value_counts() method:\n",
    "#pd.set_option('display.max_rows', None)\n",
    "#print(dataCreditScoring['total_income'].sort_values())\n",
    "#based on the data we create some group based on income level\n",
    "\n",
    "#Create function which will return income group based on total_income.\n",
    "def define_income_group(income):\n",
    "    try:\n",
    "        if income <= 30000:\n",
    "            return '0-30k'\n",
    "        if ((income >30000) &(income <=80000)):\n",
    "            return '30k-50k'\n",
    "        if ((income >80000) &(income <=120000)):\n",
    "            return '80k-120k'\n",
    "        if ((income >120000) &(income <=200000)):\n",
    "            return '120k-200k'\n",
    "        if ((income >200000) &(income <=300000)):\n",
    "            return '200k-300k'\n",
    "        if income > 300000:\n",
    "            return 'more than 300k'\n",
    "        return 'None' \n",
    "    except:\n",
    "        return 'found error in income'\n",
    "\n",
    "#print(define_income_group(125832.259))\n",
    "    \n",
    "#added new column 'income_group' to the dataframe\n",
    "dataCreditScoring['income_group']=dataCreditScoring['total_income'].apply(define_income_group)\n",
    "#print(dataCreditScoring.head(20))# print to check if new column added successfully\n",
    "\n",
    "#creating pivot table.\n",
    "data_pivot_income = dataCreditScoring.pivot_table(index='income_group', columns='isDefaulter', values='debt', aggfunc='count')\n",
    "data_pivot_income['% of defaulter'] = (data_pivot_income['defaulter']/(data_pivot_income['Nodefaulter']+data_pivot_income['defaulter'])*100).round(2)\n",
    "print(data_pivot_income.sort_values('% of defaulter')) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. No such relationship found between the income group and % of defaulter \n",
    "2. The people with highest level income group are mostly defaulter but it's just 1 record there for that category people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How do different loan purposes affect on-time repayment of the loan?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isDefaulter   Nodefaulter  defaulter  % of defaulter\n",
      "purpose_main                                        \n",
      "house                3513        256            6.79\n",
      "real estate          6365        526            7.63\n",
      "wedding              2119        186            8.07\n",
      "education            3594        370            9.33\n",
      "car                  3870        402            9.41\n"
     ]
    }
   ],
   "source": [
    "data_pivot_purpose = dataCreditScoring.pivot_table(index='purpose_main', columns='isDefaulter', values='debt', aggfunc='count')\n",
    "data_pivot_purpose['% of defaulter'] = (data_pivot_purpose['defaulter']/(data_pivot_purpose['Nodefaulter']+data_pivot_purpose['defaulter'])*100).round(2)\n",
    "print(data_pivot_purpose.sort_values('% of defaulter')) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. People who take loan for house generally pays loan on time.\n",
    "2. Those who take loan for education or car are highest in terms of '% of defaulter'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. General conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My General Analysis is as follows:\n",
    "1. People whose marital status are among ('widow/widower, divorced, married) and having no kids will have more probabily to pay loan on time.\n",
    "2. As whole data in 'days_employed' column are invalid so we will get some more detail from the team before deleting the whole column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall conclusion\n",
    "<br/>\n",
    "<div>After analysing the final data with the help of pivot table, we got following observation:\n",
    "    <br/>\n",
    "<ol>\n",
    "    <li>People with no kids generally pays loan on time.</li>\n",
    "<li>If the person who is applying for the loan fall under the category (Widow / widower, Divorced, Married) generally pays loan on time. Defaulters are high for 'civil partnership and unmarried people' category people.</li>\n",
    "<li>People who take loan for house purpose generally pays loan on time.</li>\n",
    "</ol>  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Readiness Checklist\n",
    "\n",
    "Put 'x' in the completed points. Then press Shift + Enter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  file open;\n",
    "- [x]  file examined;\n",
    "- [x]  missing values defined;\n",
    "- [x]  missing values are filled;\n",
    "- [x]  an explanation of which missing value types were detected;\n",
    "- [x]  explanation for the possible causes of missing values;\n",
    "- [x]  an explanation of how the blanks are filled;\n",
    "- [x]  replaced the real data type with an integer;\n",
    "- [x]  an explanation of which method is used to change the data type and why;\n",
    "- [x]  duplicates deleted;\n",
    "- [x]  an explanation of which method is used to find and remove duplicates;\n",
    "- [x]  description of the possible reasons for the appearance of duplicates in the data;\n",
    "- [x]  data is categorized;\n",
    "- [x]  an explanation of the principle of data categorization;\n",
    "- [x]  an answer to the question \"Is there a relation between having kids and repaying a loan on time?\";\n",
    "- [x]  an answer to the question \" Is there a relation between marital status and repaying a loan on time?\";\n",
    "- [x]   an answer to the question \" Is there a relation between income level and repaying a loan on time?\";\n",
    "- [x]  an answer to the question \" How do different loan purposes affect on-time repayment of the loan?\"\n",
    "- [x]  conclusions are present on each stage;\n",
    "- [x]  a general conclusion is made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
